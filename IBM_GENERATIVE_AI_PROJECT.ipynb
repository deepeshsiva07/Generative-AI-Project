{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Import**"
      ],
      "metadata": {
        "id": "MRcKA8fcuyxc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hq5oruZhkMAQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create character mappings**"
      ],
      "metadata": {
        "id": "wrT_AoKXs6lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "char_to_index = {char: i for i, char in enumerate(chars)}\n",
        "index_to_char = {i: char for i, char in enumerate(chars)}"
      ],
      "metadata": {
        "id": "aCKsEK8WtMbU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate training data**"
      ],
      "metadata": {
        "id": "p4ZKFdcqtTNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 20\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - max_len, step):\n",
        "    sentences.append(text[i:i + max_len])\n",
        "    next_chars.append(text[i + max_len])"
      ],
      "metadata": {
        "id": "JBkEL4KOtWCy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vectorize input and output**"
      ],
      "metadata": {
        "id": "vOYXSffttbdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sentences), max_len, len(chars)), dtype=np.float32)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.float32)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, char_to_index[char]] = 1\n",
        "    y[i, char_to_index[next_chars[i]]] = 1\n"
      ],
      "metadata": {
        "id": "1A7aPeZZtiID"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build the model**"
      ],
      "metadata": {
        "id": "k-2y_KXRtnip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    LSTM(128, input_shape=(max_len, len(chars))),\n",
        "    Dense(len(chars), activation='softmax')\n",
        "])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "s5-HCGVztxQy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model**"
      ],
      "metadata": {
        "id": "5RNE8FY8t2OU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, batch_size=100, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0nkStNtt8Oh",
        "outputId": "ae3fa991-3d7d-41de-9edc-4c6e9b1e1a1b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.8696\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8626\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.8557\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.8490\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.8423\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.8354\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8290\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.8239\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8188\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79de401b5c00>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to generate film names**"
      ],
      "metadata": {
        "id": "RIRNPE8cuDHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_film_name(seed=None, temperature=1.0):\n",
        "    if seed is None:\n",
        "        start_index = random.randint(0, len(text) - max_len - 1)\n",
        "        seed = text[start_index:start_index + max_len]\n",
        "    generated = seed\n",
        "    for _ in range(40):\n",
        "        x_pred = np.zeros((1, max_len, len(chars)))\n",
        "        for t, char in enumerate(seed):\n",
        "            x_pred[0, t, char_to_index[char]] = 1\n",
        "\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds, temperature)\n",
        "        next_char = index_to_char[next_index]\n",
        "\n",
        "        generated += next_char\n",
        "        seed = seed[1:] + next_char\n",
        "    return generated"
      ],
      "metadata": {
        "id": "w7fWWf48uJp5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper function to sample an index from a probability array**"
      ],
      "metadata": {
        "id": "2UupD_YbuS_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "HgRn9qM4ucNn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate film names**"
      ],
      "metadata": {
        "id": "q3LKK3bMuirO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(10):\n",
        "    print(generate_film_name() + \",\", end=\" \")\n",
        "    print(generate_film_name())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYEq95ugusTd",
        "outputId": "74f676db-ba9e-4ec5-91a5-694cae8432ae"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "on Pulp Fiction The thetKktIigenr ltnrnemTKrcghretiKiDrD m o, c Park Avatar TitaniottgvlnntFeri TihiRhTm itk etD  nTearoih\n",
            "tion Harry Potter IneM FthiDRhh FtredemvhFmihiosIe ivLKkm  r, lp Fiction The Lord nae sp rxFinre Tetinrhhi omcFoint eegse \n",
            "The Shawshank Redempet  r ogt iaFPtetkhirrKA  t rr hhnmi f t, rk Avatar Titanic Th aTaheTh  tDi rcgt he  hgferAl hngTDmrhm\n",
            "hawshank Redemption TtmTe gekeyinerD dK vitstgn ToomLTiTtA  , he Godfather JurassiriLtgmT imrharRtt  trh etch rTFrrDgKho t\n",
            "tter Indiana Jones B eIi imI ntfhnr  cnr hegmnTaigoo h  kha , vatar Titanic The MaatFxLo e  T Trnanttdtx  ttmet ee enzefeK\n",
            "o the Future The Dar r   a TinDemnkggohe a oe  Lhtntn ttgmeh,  The Godfather Jurasetn hegieeLomg deTtknegeAaK e hx htfhg K\n",
            "rk Knight The Lion K  hthLlnhrhhal  TLsTh eFas gnhinfeThs Tl, tion The Lord of the heg fTlkg  gL  ih  ktivtG rF ir gmo  tm\n",
            "ture The Dark KnightcggT egdDgeFesiitKgik TiFhTfr meKsTenher, ht The Lion King Finhsgd LmKtxinrDv m nsciiehlTteT tirehiea \n",
            "mption Harry Potter Athnm KneiT ItLolore r mIt RtReDLthnetee,  Jurassic Park Avata teg nIi t ta ihirmithtfnDtnteLeAm   ha \n",
            "ngs The Shawshank RedTtge aTo elAiormr DnnaeLegtFieoshKh i o, ght The Lion King Fim TiFL itksi nvnehLgiiT ehkfeetRnenAemst\n"
          ]
        }
      ]
    }
  ]
}